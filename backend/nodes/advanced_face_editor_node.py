import asyncio
import subprocess
import sys
import os
import json
from pathlib import Path
from typing import Dict, Any, Optional, List

# Optional imports - provide fallbacks if not available
try:
    import cv2
    import numpy as np
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False
    print("Warning: OpenCV not available. Advanced face editor will use fallback mode.")

from schemas.schemas import WorkflowNode, NodeStatus
from nodes.base_node import BaseNode
from api.websocket import websocket_manager


class AdvancedFaceEditorNode(BaseNode):
    """Advanced face editor with auto-detection, model loading, and segment selection"""
    
    def __init__(self, node: WorkflowNode):
        super().__init__(node)
        
    def get_required_parameters(self) -> list:
        return ["input_dir"]
    
    async def execute(self, execution_context: Dict[str, Any]) -> Dict[str, Any]:
        """Execute advanced face editing with auto-detection and model loading"""
        try:
            await self.update_status(NodeStatus.RUNNING, "Starting Advanced Face Editor...")
            
            # Get parameters
            input_dir = self.get_parameter("input_dir")
            face_type = self.get_parameter("face_type", "full_face")
            detection_model = self.get_parameter("detection_model", "VGGFace2")
            similarity_threshold = self.get_parameter("similarity_threshold", 0.6)
            
            input_path = Path(input_dir)
            if not input_path.exists():
                return {"success": False, "error": f"Input directory does not exist: {input_path}"}
            
            # Update progress
            await self.update_progress(10, "Scanning for face images...")
            
            # Find all face images
            face_files = self._find_face_images(input_path)
            if not face_files:
                return {"success": False, "error": "No face images found in input directory"}
            
            await self.log_message("info", f"Found {len(face_files)} face images")
            await self.update_progress(20, f"Processing {len(face_files)} face images...")
            
            # Detect faces and return face list for frontend
            await self.update_progress(30, "Detecting faces...")
            face_data = await self.detect_faces(input_path, face_files, detection_model, face_type, similarity_threshold)
            
            await self.update_progress(100, "Face detection completed")
            await self.log_message("info", "Advanced face editing interface ready")
            
            # Set output path
            self.set_output_path("output_dir", str(input_path))
            
            return {
                "success": True,
                "output_path": str(input_path),
                "face_images": face_data,
                "faces_processed": len(face_files),
                "message": "Advanced face editing interface ready"
            }
            
        except Exception as e:
            error_msg = f"Advanced face editor failed: {str(e)}"
            await self.update_status(NodeStatus.ERROR, error_msg)
            await self.log_message("error", error_msg)
            return {"success": False, "error": error_msg}
    
    def _find_face_images(self, input_path: Path) -> List[Path]:
        """Find all face images in the input directory"""
        extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']
        face_files = []
        
        for ext in extensions:
            face_files.extend(input_path.glob(f"*{ext}"))
            face_files.extend(input_path.glob(f"*{ext.upper()}"))
        
        # Sort files by filename for consistent ordering
        return sorted(face_files, key=lambda x: x.name)
    
    async def detect_faces(self, input_path: Path, face_files: List[Path], detection_model: str, face_type: str, similarity_threshold: float) -> List[Dict]:
        """Detect faces in images and return face data for frontend"""
        try:
            await self.log_message("info", f"Detecting faces using {detection_model} model...")
            
            face_data = []
            for i, face_file in enumerate(face_files):
                try:
                    # Create face data entry
                    face_entry = {
                        "id": f"face_{i}",
                        "filename": face_file.name,
                        "filePath": str(face_file),
                        "thumbnailUrl": None,  # Will be generated by frontend
                        "segmentationPolygon": None,
                        "landmarks": None,
                        "selected": False,
                        "active": False
                    }
                    
                    # Extract landmarks if CV2 is available
                    if CV2_AVAILABLE:
                        landmarks = await self._extract_landmarks(face_file)
                        face_entry["landmarks"] = landmarks
                    
                    face_data.append(face_entry)
                    
                    # Update progress
                    progress = 30 + (i / len(face_files)) * 40
                    await self.update_progress(progress, f"Processing {face_file.name}")
                    
                except Exception as e:
                    await self.log_message("warning", f"Failed to process {face_file.name}: {str(e)}")
                    continue
            
            await self.log_message("info", f"Detected {len(face_data)} faces successfully")
            return face_data
            
        except Exception as e:
            await self.log_message("error", f"Face detection failed: {str(e)}")
            return []
    
    async def load_bisenet_model(self) -> Dict[str, Any]:
        """Load BiSeNet segmentation model"""
        try:
            await self.log_message("info", "Loading BiSeNet segmentation model...")
            
            # Try to load BiSeNet model from machine-video-editor
            machine_editor_path = Path("/Volumes/MacOSNew/SourceCode/deepface-editor/machine-video-editor-0.8.2/resources/external/python")
            
            if machine_editor_path.exists():
                sys.path.append(str(machine_editor_path))
                
                try:
                    # Import BiSeNet model (if available)
                    from scripts.alignment_embeding.SegIEPolys import SegIEPolys
                    
                    # Initialize BiSeNet model
                    bisenet_model = SegIEPolys()
                    await self.log_message("info", "BiSeNet model loaded successfully")
                    
                    return {
                        "success": True,
                        "message": "BiSeNet model loaded successfully",
                        "model_type": "BiSeNet"
                    }
                    
                except ImportError:
                    await self.log_message("warning", "BiSeNet model not available, using fallback")
                    return {
                        "success": True,
                        "message": "BiSeNet model not available, using fallback",
                        "model_type": "fallback"
                    }
            else:
                await self.log_message("warning", "Machine Video Editor not found, using fallback")
                return {
                    "success": True,
                    "message": "Machine Video Editor not found, using fallback",
                    "model_type": "fallback"
                }
                
        except Exception as e:
            await self.log_message("error", f"Failed to load BiSeNet model: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }
    
    async def generate_segmentation_masks(self, face_images: List[Dict], eyebrow_expand_mod: int = 1) -> Dict[str, Any]:
        """Generate segmentation masks for face images"""
        try:
            await self.log_message("info", f"Generating segmentation masks with eyebrow expand mod: {eyebrow_expand_mod}")
            
            processed_count = 0
            face_data = {}
            
            for face_image in face_images:
                try:
                    face_file = Path(face_image["filePath"])
                    
                    # Generate mock segmentation polygon (in real implementation, use BiSeNet)
                    if CV2_AVAILABLE:
                        # Load image to get dimensions
                        img = cv2.imread(str(face_file))
                        if img is not None:
                            height, width = img.shape[:2]
                            
                            # Generate mock polygon (face outline)
                            polygon = [
                                [width * 0.2, height * 0.1],  # Top left
                                [width * 0.8, height * 0.1],  # Top right
                                [width * 0.9, height * 0.4],  # Right cheek
                                [width * 0.8, height * 0.7],  # Right jaw
                                [width * 0.5, height * 0.9],  # Chin
                                [width * 0.2, height * 0.7],  # Left jaw
                                [width * 0.1, height * 0.4],  # Left cheek
                            ]
                            
                            # Apply eyebrow expansion
                            if eyebrow_expand_mod > 1:
                                polygon = self._expand_eyebrow_region(polygon, eyebrow_expand_mod, width, height)
                            
                            face_data[face_image["id"]] = {
                                "segmentation_polygon": polygon
                            }
                            processed_count += 1
                    
                    await self.log_message("info", f"Generated mask for {face_file.name}")
                    
                except Exception as e:
                    await self.log_message("warning", f"Failed to generate mask for {face_image['filename']}: {str(e)}")
                    continue
            
            await self.log_message("info", f"Generated segmentation masks for {processed_count} faces")
            
            return {
                "success": True,
                "processed_count": processed_count,
                "face_data": face_data,
                "message": f"Generated masks for {processed_count} faces"
            }
            
        except Exception as e:
            await self.log_message("error", f"Mask generation failed: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }
    
    async def embed_mask_polygons(self, face_images: List[Dict], eyebrow_expand_mod: int = 1) -> Dict[str, Any]:
        """Embed mask polygons into face images for training"""
        try:
            await self.log_message("info", f"Embedding mask polygons with eyebrow expand mod: {eyebrow_expand_mod}")
            
            processed_count = 0
            
            for face_image in face_images:
                try:
                    face_file = Path(face_image["filePath"])
                    
                    # In real implementation, embed segmentation data into image metadata
                    if CV2_AVAILABLE and face_image.get("segmentationPolygon"):
                        img = cv2.imread(str(face_file))
                        if img is not None:
                            # Embed polygon data (simplified - in real implementation, use DFL format)
                            polygon_data = face_image["segmentationPolygon"]
                            
                            # Save embedded image (simplified)
                            output_file = face_file.parent / f"embedded_{face_file.name}"
                            cv2.imwrite(str(output_file), img)
                            
                            processed_count += 1
                            await self.log_message("info", f"Embedded polygons for {face_file.name}")
                    
                except Exception as e:
                    await self.log_message("warning", f"Failed to embed polygons for {face_image['filename']}: {str(e)}")
                    continue
            
            await self.log_message("info", f"Embedded mask polygons for {processed_count} faces")
            await self.log_message("info", "Images ready for training!")
            
            return {
                "success": True,
                "processed_count": processed_count,
                "message": f"Embedded polygons for {processed_count} faces. Images ready for training!"
            }
            
        except Exception as e:
            await self.log_message("error", f"Polygon embedding failed: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }
    
    async def _extract_landmarks(self, face_file: Path) -> List[List[float]]:
        """Extract facial landmarks from image"""
        try:
            if not CV2_AVAILABLE:
                return []
            
            img = cv2.imread(str(face_file))
            if img is None:
                return []
            
            # Mock landmarks (in real implementation, use dlib or similar)
            height, width = img.shape[:2]
            
            # Generate mock facial landmarks
            landmarks = [
                [width * 0.3, height * 0.3],  # Left eye center
                [width * 0.7, height * 0.3],  # Right eye center
                [width * 0.5, height * 0.5],  # Nose tip
                [width * 0.4, height * 0.7],  # Left mouth corner
                [width * 0.6, height * 0.7],  # Right mouth corner
            ]
            
            return landmarks
            
        except Exception as e:
            await self.log_message("warning", f"Failed to extract landmarks from {face_file.name}: {str(e)}")
            return []
    
    def _expand_eyebrow_region(self, polygon: List[List[float]], expand_mod: int, width: int, height: int) -> List[List[float]]:
        """Expand eyebrow region of polygon based on expand_mod parameter"""
        try:
            # Find eyebrow region (top part of polygon)
            eyebrow_points = []
            for point in polygon:
                if point[1] < height * 0.3:  # Top 30% of face
                    eyebrow_points.append(point)
            
            # Expand eyebrow region
            expanded_polygon = []
            for point in polygon:
                if point[1] < height * 0.3:
                    # Expand upward
                    expanded_point = [point[0], point[1] - (expand_mod * height * 0.02)]
                    expanded_polygon.append(expanded_point)
                else:
                    expanded_polygon.append(point)
            
            return expanded_polygon
            
        except Exception as e:
            # Log warning synchronously since this is not an async method
            print(f"Warning: Failed to expand eyebrow region: {str(e)}")
            return polygon
    
    async def _load_face_model(self, model_name: str):
        """Load the specified face detection model"""
        if model_name == "VGGFace2":
            # Use the VGGFace2 model from machine-video-editor
            model_path = "/Volumes/MacOSNew/SourceCode/deepface-editor/machine-video-editor-0.8.2/resources/external/python/scripts/sort/models/vggface2_resnet50_v2.h5"
            
            if not Path(model_path).exists():
                raise FileNotFoundError(f"VGGFace2 model not found at: {model_path}")
            
            # Import and load the model
            sys.path.append("/Volumes/MacOSNew/SourceCode/deepface-editor/machine-video-editor-0.8.2/resources/external/python/scripts/sort")
            
            from face_sort import VGGFace2
            return VGGFace2()
        
        else:
            raise ValueError(f"Unsupported model: {model_name}")
    
    async def _extract_face_features(self, face_files: List[Path], model) -> List[Dict]:
        """Extract features from face images"""
        features = []
        
        if not CV2_AVAILABLE:
            # Fallback mode - create mock features
            await self.log_message("info", "Using fallback mode (OpenCV not available)")
            for i, face_file in enumerate(face_files):
                features.append({
                    "file_path": str(face_file),
                    "filename": face_file.name,
                    "features": [0.1] * 10,  # Mock features
                    "image_shape": (256, 256, 3)  # Mock shape
                })
                
                progress = 40 + (i / len(face_files)) * 20
                await self.update_progress(progress, f"Processing {face_file.name} (fallback mode)")
            return features
        
        for i, face_file in enumerate(face_files):
            try:
                # Load and process the face image
                face_image = cv2.imread(str(face_file))
                if face_image is None:
                    continue
                
                # Extract features using the model
                face_features = model.predict(face_image)
                
                features.append({
                    "file_path": str(face_file),
                    "filename": face_file.name,
                    "features": face_features.tolist(),
                    "image_shape": face_image.shape
                })
                
                # Update progress
                progress = 40 + (i / len(face_files)) * 20
                await self.update_progress(progress, f"Extracting features from {face_file.name}")
                
            except Exception as e:
                await self.log_message("warning", f"Failed to process {face_file.name}: {str(e)}")
                continue
        
        return features
    
    async def _group_faces_by_similarity(self, face_features: List[Dict], threshold: float) -> List[List[Dict]]:
        """Group faces by similarity using clustering"""
        if len(face_features) < 2:
            return [face_features]
        
        if not CV2_AVAILABLE:
            # Fallback mode - simple grouping
            await self.log_message("info", "Using simple grouping (fallback mode)")
            return [face_features]  # Return all faces as one group
        
        # Extract feature vectors
        features_matrix = np.array([f["features"] for f in face_features])
        
        # Use the VGGFace2 similarity method
        from face_sort import VGGFace2
        model = VGGFace2()
        
        # Calculate similarity matrix
        similarity_matrix = np.zeros((len(face_features), len(face_features)))
        for i in range(len(face_features)):
            for j in range(i+1, len(face_features)):
                similarity = model.find_cosine_similiarity(
                    np.array(face_features[i]["features"]),
                    np.array(face_features[j]["features"])
                )
                similarity_matrix[i][j] = similarity
                similarity_matrix[j][i] = similarity
        
        # Simple clustering based on threshold
        groups = []
        used = set()
        
        for i in range(len(face_features)):
            if i in used:
                continue
            
            group = [face_features[i]]
            used.add(i)
            
            for j in range(i+1, len(face_features)):
                if j in used:
                    continue
                
                if similarity_matrix[i][j] < threshold:
                    group.append(face_features[j])
                    used.add(j)
            
            groups.append(group)
        
        return groups
    
    async def _prepare_editing_interface(self, face_groups: List[List[Dict]], face_files: List[Path]) -> Dict:
        """Prepare data for the face editing interface"""
        editing_data = {
            "face_groups": [],
            "total_faces": len(face_files),
            "total_groups": len(face_groups),
            "interface_type": "advanced_face_editor"
        }
        
        for group_idx, group in enumerate(face_groups):
            group_data = {
                "group_id": group_idx,
                "faces": [],
                "representative_face": group[0]["filename"] if group else None
            }
            
            for face in group:
                face_data = {
                    "filename": face["filename"],
                    "file_path": face["file_path"],
                    "image_shape": face["image_shape"],
                    "features": face["features"][:10]  # First 10 features for display
                }
                group_data["faces"].append(face_data)
            
            editing_data["face_groups"].append(group_data)
        
        return editing_data
    
    async def _launch_gui_editor(self, input_path: Path, face_files: List[Path], face_type: str, detection_model: str, similarity_threshold: float) -> Dict[str, Any]:
        """Launch the Machine Video Editor or create a similar interface"""
        try:
            await self.log_message("info", "Launching Machine Video Editor...")
            
            # Try to launch the actual Machine Video Editor first
            machine_editor_path = Path("/Volumes/MacOSNew/SourceCode/deepface-editor/machine-video-editor-0.8.2/machine-video-editor")
            
            if machine_editor_path.exists():
                await self.log_message("info", "Found Machine Video Editor executable, launching...")
                
                # Launch the Machine Video Editor
                process = await asyncio.create_subprocess_exec(
                    str(machine_editor_path),
                    cwd=str(machine_editor_path.parent),
                    stdout=asyncio.subprocess.PIPE,
                    stderr=asyncio.subprocess.PIPE
                )
                
                await self.log_message("info", "Machine Video Editor launched successfully!")
                return {"success": True, "message": "Machine Video Editor launched successfully"}
            
            else:
                # Fallback: Create a Machine Video Editor-style interface
                await self.log_message("info", "Machine Video Editor not found, creating similar interface...")
                return await self._create_machine_editor_interface(input_path, face_files, face_type, detection_model, similarity_threshold)
            
        except Exception as e:
            await self.log_message("error", f"Failed to launch Machine Video Editor: {str(e)}")
            # Fallback to custom interface
            return await self._create_machine_editor_interface(input_path, face_files, face_type, detection_model, similarity_threshold)
    
    async def _create_machine_editor_interface(self, input_path: Path, face_files: List[Path], face_type: str, detection_model: str, similarity_threshold: float) -> Dict[str, Any]:
        """Create a Machine Video Editor-style interface using their Python scripts"""
        try:
            await self.log_message("info", "Creating Machine Video Editor-style interface...")
            
            # Create a Python script that uses the Machine Video Editor's face sorting capabilities
            gui_script = self._create_machine_editor_script(input_path, face_files, face_type, detection_model, similarity_threshold)
            
            # Write the script to a temporary file
            script_path = input_path / "machine_editor_interface.py"
            with open(script_path, 'w') as f:
                f.write(gui_script)
            
            await self.log_message("info", f"Created Machine Video Editor interface script at {script_path}")
            
            # Launch the interface as a subprocess
            process = await asyncio.create_subprocess_exec(
                sys.executable, str(script_path),
                cwd=str(input_path),
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            await self.log_message("info", "Machine Video Editor interface launched successfully!")
            
            return {"success": True, "message": "Machine Video Editor interface launched successfully"}
            
        except Exception as e:
            await self.log_message("error", f"Failed to create Machine Video Editor interface: {str(e)}")
            return {"success": False, "error": str(e)}
    
    def _create_machine_editor_script(self, input_path: Path, face_files: List[Path], face_type: str, detection_model: str, similarity_threshold: float) -> str:
        """Create a Machine Video Editor-style interface script"""
        return f'''
import tkinter as tk
from tkinter import ttk, messagebox, filedialog
import os
import sys
from pathlib import Path
import json
import threading
from PIL import Image, ImageTk

# Add Machine Video Editor Python path
machine_editor_path = "/Volumes/MacOSNew/SourceCode/deepface-editor/machine-video-editor-0.8.2/resources/external/python"
sys.path.append(machine_editor_path)

# Try to import Machine Video Editor modules
try:
    from scripts.sort.face_sort import VGGFace2
    from scripts.sort.DFLJPG import DFLJPG
    from scripts.sort.DFLPNG import DFLPNG
    MACHINE_EDITOR_AVAILABLE = True
except ImportError:
    MACHINE_EDITOR_AVAILABLE = False
    print("Warning: Machine Video Editor modules not available")

class MachineVideoEditorInterface:
    def __init__(self, root, input_path, face_files, face_type, detection_model, similarity_threshold):
        self.root = root
        self.input_path = Path(input_path)
        self.face_files = [Path(f) for f in face_files]
        self.face_type = face_type
        self.detection_model = detection_model
        self.similarity_threshold = similarity_threshold
        
        # State variables
        self.selected_faces = set()
        self.face_images = {{}}
        self.face_data = {{}}
        self.detection_profiles = {{"default": []}}
        self.current_profile = "default"
        self.frame_size = 25  # Percentage
        self.sort_mode = "filename"
        self.filter_range = (0, len(face_files))
        
        self.setup_ui()
        self.load_faces()
    
    def setup_ui(self):
        self.root.title("Machine Video Editor - Advanced Face Editor")
        self.root.geometry("1400x900")
        self.root.configure(bg='#2b2b2b')
        
        # Create main paned window
        main_paned = ttk.PanedWindow(self.root, orient=tk.HORIZONTAL)
        main_paned.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        # Left Panel - File Explorer
        self.setup_left_panel(main_paned)
        
        # Center Panel - Face Grid
        self.setup_center_panel(main_paned)
        
        # Right Panel - Detection Management
        self.setup_right_panel(main_paned)
        
        # Configure paned window weights
        main_paned.add(self.left_frame, weight=1)
        main_paned.add(self.center_frame, weight=3)
        main_paned.add(self.right_frame, weight=1)
    
    def setup_left_panel(self, parent):
        """Setup the left file explorer panel"""
        self.left_frame = ttk.LabelFrame(parent, text="Project Explorer", padding=10)
        
        # Project structure tree
        tree_frame = ttk.Frame(self.left_frame)
        tree_frame.pack(fill=tk.BOTH, expand=True)
        
        self.tree = ttk.Treeview(tree_frame)
        self.tree.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        
        # Add scrollbar
        tree_scroll = ttk.Scrollbar(tree_frame, orient=tk.VERTICAL, command=self.tree.yview)
        tree_scroll.pack(side=tk.RIGHT, fill=tk.Y)
        self.tree.configure(yscrollcommand=tree_scroll.set)
        
        # Populate tree
        self.populate_file_tree()
        
        # Actions frame
        actions_frame = ttk.LabelFrame(self.left_frame, text="Actions", padding=5)
        actions_frame.pack(fill=tk.X, pady=(10, 0))
        
        ttk.Button(actions_frame, text="Open Images", command=self.open_images).pack(fill=tk.X, pady=2)
        ttk.Button(actions_frame, text="Open Slideshow", command=self.open_slideshow).pack(fill=tk.X, pady=2)
        ttk.Button(actions_frame, text="Refresh", command=self.refresh_tree).pack(fill=tk.X, pady=2)
    
    def setup_center_panel(self, parent):
        """Setup the center face grid panel"""
        self.center_frame = ttk.LabelFrame(parent, text="Face Images", padding=10)
        
        # Top controls
        controls_frame = ttk.Frame(self.center_frame)
        controls_frame.pack(fill=tk.X, pady=(0, 10))
        
        # View mode buttons
        view_frame = ttk.LabelFrame(controls_frame, text="View", padding=5)
        view_frame.pack(side=tk.LEFT, padx=(0, 10))
        
        ttk.Button(view_frame, text="📋", command=self.set_list_view).pack(side=tk.LEFT, padx=2)
        ttk.Button(view_frame, text="⊞", command=self.set_grid_view).pack(side=tk.LEFT, padx=2)
        
        # Frame size control
        size_frame = ttk.LabelFrame(controls_frame, text="Frame Size", padding=5)
        size_frame.pack(side=tk.LEFT, padx=(0, 10))
        
        self.size_var = tk.StringVar(value="25%")
        size_combo = ttk.Combobox(size_frame, textvariable=self.size_var, 
                                 values=["10%", "25%", "50%", "75%", "100%"], 
                                 state="readonly", width=8)
        size_combo.pack(side=tk.LEFT)
        size_combo.bind('<<ComboboxSelected>>', self.on_size_change)
        
        # Sort and Filter controls
        filter_frame = ttk.LabelFrame(controls_frame, text="Sort & Filter", padding=5)
        filter_frame.pack(side=tk.LEFT, padx=(0, 10))
        
        self.sort_var = tk.StringVar(value="filename")
        sort_combo = ttk.Combobox(filter_frame, textvariable=self.sort_var,
                                 values=["filename", "date", "size", "similarity"], 
                                 state="readonly", width=10)
        sort_combo.pack(side=tk.LEFT, padx=(0, 5))
        
        ttk.Button(filter_frame, text="Sort", command=self.sort_faces).pack(side=tk.LEFT, padx=2)
        ttk.Button(filter_frame, text="Filter", command=self.filter_faces).pack(side=tk.LEFT, padx=2)
        
        # Frame range controls
        range_frame = ttk.LabelFrame(controls_frame, text="Frame Range", padding=5)
        range_frame.pack(side=tk.LEFT)
        
        ttk.Label(range_frame, text="Start:").pack(side=tk.LEFT)
        self.start_frame_var = tk.StringVar(value="0")
        ttk.Entry(range_frame, textvariable=self.start_frame_var, width=8).pack(side=tk.LEFT, padx=2)
        
        ttk.Label(range_frame, text="End:").pack(side=tk.LEFT, padx=(5, 0))
        self.end_frame_var = tk.StringVar(value=str(len(self.face_files)))
        ttk.Entry(range_frame, textvariable=self.end_frame_var, width=8).pack(side=tk.LEFT, padx=2)
        
        # Face grid with scrollbars
        grid_frame = ttk.Frame(self.center_frame)
        grid_frame.pack(fill=tk.BOTH, expand=True)
        
        # Create canvas for face grid
        self.canvas = tk.Canvas(grid_frame, bg='#1e1e1e')
        self.scrollbar_v = ttk.Scrollbar(grid_frame, orient=tk.VERTICAL, command=self.canvas.yview)
        self.scrollbar_h = ttk.Scrollbar(grid_frame, orient=tk.HORIZONTAL, command=self.canvas.xview)
        
        self.canvas.configure(yscrollcommand=self.scrollbar_v.set, xscrollcommand=self.scrollbar_h.set)
        
        # Pack canvas and scrollbars
        self.canvas.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        self.scrollbar_v.pack(side=tk.RIGHT, fill=tk.Y)
        self.scrollbar_h.pack(side=tk.BOTTOM, fill=tk.X)
        
        # Create frame inside canvas for face images
        self.face_frame = ttk.Frame(self.canvas)
        self.canvas.create_window((0, 0), window=self.face_frame, anchor="nw")
        
        # Bind canvas events
        self.canvas.bind('<Configure>', self.on_canvas_configure)
        self.canvas.bind('<MouseWheel>', self.on_mousewheel)
    
    def setup_right_panel(self, parent):
        """Setup the right detection management panel"""
        self.right_frame = ttk.LabelFrame(parent, text="Detection Management", padding=10)
        
        # Frame count
        count_frame = ttk.Frame(self.right_frame)
        count_frame.pack(fill=tk.X, pady=(0, 10))
        
        ttk.Label(count_frame, text=f"Frame count: {{len(self.face_files)}}", 
                 font=("Arial", 10, "bold")).pack()
        
        # Detection Profiles
        profiles_frame = ttk.LabelFrame(self.right_frame, text="Detection Profiles", padding=5)
        profiles_frame.pack(fill=tk.X, pady=(0, 10))
        
        self.profile_var = tk.StringVar(value="default")
        profile_combo = ttk.Combobox(profiles_frame, textvariable=self.profile_var,
                                    values=list(self.detection_profiles.keys()),
                                    state="readonly")
        profile_combo.pack(fill=tk.X, pady=2)
        
        profile_buttons = ttk.Frame(profiles_frame)
        profile_buttons.pack(fill=tk.X, pady=2)
        
        ttk.Button(profile_buttons, text="Add Name", command=self.add_profile).pack(side=tk.LEFT, padx=1)
        ttk.Button(profile_buttons, text="Remove", command=self.remove_profile).pack(side=tk.LEFT, padx=1)
        ttk.Button(profile_buttons, text="Reset", command=self.reset_profile).pack(side=tk.LEFT, padx=1)
        ttk.Button(profile_buttons, text="Remove Selected", command=self.remove_selected).pack(side=tk.LEFT, padx=1)
        
        # Image Information
        info_frame = ttk.LabelFrame(self.right_frame, text="Image Information", padding=5)
        info_frame.pack(fill=tk.X, pady=(0, 10))
        
        ttk.Label(info_frame, text="Face:").pack(anchor=tk.W)
        self.face_var = tk.StringVar()
        ttk.Combobox(info_frame, textvariable=self.face_var, state="readonly").pack(fill=tk.X, pady=2)
        
        ttk.Label(info_frame, text="Parent frame folder:").pack(anchor=tk.W, pady=(5, 0))
        parent_frame = ttk.Frame(info_frame)
        parent_frame.pack(fill=tk.X, pady=2)
        
        self.parent_folder_var = tk.StringVar()
        ttk.Entry(parent_frame, textvariable=self.parent_folder_var).pack(side=tk.LEFT, fill=tk.X, expand=True)
        ttk.Button(parent_frame, text="📁", command=self.browse_parent_folder).pack(side=tk.RIGHT, padx=(5, 0))
        
        # Embedded Detections
        embedded_frame = ttk.LabelFrame(self.right_frame, text="Embedded Detections", padding=5)
        embedded_frame.pack(fill=tk.X, pady=(0, 10))
        
        self.set_faces_var = tk.BooleanVar()
        ttk.Checkbutton(embedded_frame, text="Set faces to parent frames", 
                       variable=self.set_faces_var).pack(anchor=tk.W)
        
        ttk.Button(embedded_frame, text="Import face data", command=self.import_face_data).pack(fill=tk.X, pady=2)
        ttk.Button(embedded_frame, text="Embed Mask Polygons", command=self.embed_mask_polygons).pack(fill=tk.X, pady=2)
        
        # Eyebrow expand control
        eyebrow_frame = ttk.Frame(embedded_frame)
        eyebrow_frame.pack(fill=tk.X, pady=2)
        
        ttk.Label(eyebrow_frame, text="Eyebrow expand mod value between 1-4:").pack(anchor=tk.W)
        self.eyebrow_var = tk.StringVar(value="1")
        ttk.Entry(eyebrow_frame, textvariable=self.eyebrow_var, width=5).pack(anchor=tk.W)
        
        # Faces Folder
        faces_folder_frame = ttk.LabelFrame(self.right_frame, text="Faces Folder", padding=5)
        faces_folder_frame.pack(fill=tk.X, pady=(0, 10))
        
        folder_frame = ttk.Frame(faces_folder_frame)
        folder_frame.pack(fill=tk.X, pady=2)
        
        self.faces_folder_var = tk.StringVar(value=str(self.input_path))
        ttk.Entry(folder_frame, textvariable=self.faces_folder_var).pack(side=tk.LEFT, fill=tk.X, expand=True)
        ttk.Button(folder_frame, text="📁", command=self.browse_faces_folder).pack(side=tk.RIGHT, padx=(5, 0))
        
        # Checkboxes
        self.only_parent_var = tk.BooleanVar()
        ttk.Checkbutton(faces_folder_frame, text="Only parent data", 
                       variable=self.only_parent_var).pack(anchor=tk.W)
        
        self.recalculate_var = tk.BooleanVar()
        ttk.Checkbutton(faces_folder_frame, text="Recalculate face data", 
                       variable=self.recalculate_var).pack(anchor=tk.W)
        
        self.copy_embedded_var = tk.BooleanVar()
        ttk.Checkbutton(faces_folder_frame, text="Copy embedded data", 
                       variable=self.copy_embedded_var).pack(anchor=tk.W)
        
        # Open XSeg Editor button
        ttk.Button(self.right_frame, text="Open XSeg Editor", 
                  command=self.open_xseg_editor).pack(fill=tk.X, pady=(10, 0))
    
    def populate_file_tree(self):
        """Populate the file tree with project structure"""
        # Clear existing items
        for item in self.tree.get_children():
            self.tree.delete(item)
        
        # Add project structure
        project_root = self.tree.insert("", "end", text="DeepFaceLab_Workflow", open=True)
        
        # Add workspace structure
        workspace = self.tree.insert(project_root, "end", text="workspace", open=True)
        
        # Add data_src
        data_src = self.tree.insert(workspace, "end", text="data_src", open=True)
        
        # Add aligned folder (current)
        aligned = self.tree.insert(data_src, "end", text="aligned", open=True)
        self.tree.insert(aligned, "end", text=f"Open images ({{len(self.face_files)}})")
        
        # Add other folders
        self.tree.insert(data_src, "end", text="aligned_debug")
        self.tree.insert(workspace, "end", text="model")
        self.tree.insert(workspace, "end", text="data_dst.mp4")
    
    def load_faces(self):
        """Load and display face images in the grid"""
        # Clear existing images
        for widget in self.face_frame.winfo_children():
            widget.destroy()
        
        # Calculate grid dimensions
        cols = 10  # Number of columns
        face_size = int(120 * (self.frame_size / 100))  # Adjust size based on frame size
        
        for i, face_file in enumerate(self.face_files):
            row = i // cols
            col = i % cols
            
            # Create frame for each face
            face_widget = ttk.Frame(self.face_frame)
            face_widget.grid(row=row, column=col, padx=2, pady=2)
            
            # Load and resize image
            try:
                img = Image.open(face_file)
                img = img.resize((face_size, face_size), Image.Resampling.LANCZOS)
                photo = ImageTk.PhotoImage(img)
                
                # Create label with image
                img_label = ttk.Label(face_widget, image=photo)
                img_label.image = photo  # Keep a reference
                img_label.pack()
                
                # Add filename label
                filename_label = ttk.Label(face_widget, text=face_file.name, 
                                         font=("Arial", 8), foreground="white")
                filename_label.pack()
                
                # Add selection checkbox
                var = tk.BooleanVar()
                checkbox = ttk.Checkbutton(face_widget, variable=var,
                                         command=lambda f=face_file, v=var: self.toggle_selection(f, v))
                checkbox.pack()
                
                # Add bookmark button
                bookmark_btn = ttk.Button(face_widget, text="🔖", width=3,
                                         command=lambda f=face_file: self.bookmark_face(f))
                bookmark_btn.pack()
                
                # Store references
                self.face_images[face_file] = {{
                    'widget': face_widget,
                    'image': photo,
                    'checkbox': checkbox,
                    'var': var,
                    'selected': False
                }}
                
            except Exception as e:
                # Create placeholder for failed images
                placeholder = ttk.Label(face_widget, text=f"Error\\n{{face_file.name}}", 
                                      font=("Arial", 8), foreground="red")
                placeholder.pack()
        
        # Update canvas scroll region
        self.face_frame.update_idletasks()
        self.canvas.configure(scrollregion=self.canvas.bbox("all"))
    
    def toggle_selection(self, face_file, var):
        """Toggle selection of a face"""
        if var.get():
            self.selected_faces.add(face_file)
            self.face_images[face_file]['selected'] = True
            # Add green border effect
            self.face_images[face_file]['widget'].configure(relief="solid", borderwidth=2)
        else:
            self.selected_faces.discard(face_file)
            self.face_images[face_file]['selected'] = False
            # Remove border
            self.face_images[face_file]['widget'].configure(relief="flat", borderwidth=0)
    
    def bookmark_face(self, face_file):
        """Bookmark a face"""
        messagebox.showinfo("Bookmark", f"Bookmarked: {{face_file.name}}")
    
    def on_canvas_configure(self, event):
        """Handle canvas resize"""
        self.canvas.configure(scrollregion=self.canvas.bbox("all"))
    
    def on_mousewheel(self, event):
        """Handle mouse wheel scrolling"""
        self.canvas.yview_scroll(int(-1*(event.delta/120)), "units")
    
    def on_size_change(self, event):
        """Handle frame size change"""
        self.frame_size = int(self.size_var.get().replace('%', ''))
        self.load_faces()
    
    def sort_faces(self):
        """Sort faces based on selected criteria"""
        sort_mode = self.sort_var.get()
        if sort_mode == "filename":
            self.face_files.sort(key=lambda x: x.name)
        elif sort_mode == "date":
            self.face_files.sort(key=lambda x: x.stat().st_mtime)
        elif sort_mode == "size":
            self.face_files.sort(key=lambda x: x.stat().st_size)
        
        self.load_faces()
    
    def filter_faces(self):
        """Filter faces based on range"""
        try:
            start = int(self.start_frame_var.get())
            end = int(self.end_frame_var.get())
            self.face_files = self.face_files[start:end]
            self.load_faces()
        except ValueError:
            messagebox.showerror("Error", "Invalid frame range")
    
    def set_list_view(self):
        """Set list view mode"""
        messagebox.showinfo("View", "Switched to list view")
    
    def set_grid_view(self):
        """Set grid view mode"""
        messagebox.showinfo("View", "Switched to grid view")
    
    def open_images(self):
        """Open images in external viewer"""
        messagebox.showinfo("Open Images", f"Opening {{len(self.face_files)}} images")
    
    def open_slideshow(self):
        """Open slideshow mode"""
        messagebox.showinfo("Slideshow", "Opening slideshow mode")
    
    def refresh_tree(self):
        """Refresh the file tree"""
        self.populate_file_tree()
    
    def add_profile(self):
        """Add new detection profile"""
        name = tk.simpledialog.askstring("Add Profile", "Enter profile name:")
        if name:
            self.detection_profiles[name] = []
            # Update combobox
            self.profile_var.set(name)
    
    def remove_profile(self):
        """Remove current detection profile"""
        profile = self.profile_var.get()
        if profile != "default" and profile in self.detection_profiles:
            del self.detection_profiles[profile]
            self.profile_var.set("default")
    
    def reset_profile(self):
        """Reset current profile"""
        profile = self.profile_var.get()
        self.detection_profiles[profile] = []
        messagebox.showinfo("Reset", f"Reset profile: {{profile}}")
    
    def remove_selected(self):
        """Remove selected faces"""
        if self.selected_faces:
            messagebox.showinfo("Remove", f"Removing {{len(self.selected_faces)}} selected faces")
        else:
            messagebox.showwarning("Warning", "No faces selected")
    
    def browse_parent_folder(self):
        """Browse for parent frame folder"""
        folder = filedialog.askdirectory()
        if folder:
            self.parent_folder_var.set(folder)
    
    def browse_faces_folder(self):
        """Browse for faces folder"""
        folder = filedialog.askdirectory()
        if folder:
            self.faces_folder_var.set(folder)
    
    def import_face_data(self):
        """Import face data"""
        messagebox.showinfo("Import", "Importing face data...")
    
    def embed_mask_polygons(self):
        """Embed mask polygons"""
        messagebox.showinfo("Embed", "Embedding mask polygons...")
    
    def open_xseg_editor(self):
        """Open XSeg editor"""
        messagebox.showinfo("XSeg Editor", "Opening XSeg Editor...")

def main():
    # Get parameters from command line or use defaults
    input_path = sys.argv[1] if len(sys.argv) > 1 else "."
    face_files = sys.argv[2:] if len(sys.argv) > 2 else []
    
    # If no face files provided, find them in the input directory
    if not face_files:
        input_dir = Path(input_path)
        face_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']
        for ext in face_extensions:
            face_files.extend([str(f) for f in input_dir.glob(f"*{{ext}}")])
            face_files.extend([str(f) for f in input_dir.glob(f"*{{ext.upper()}}")])
    
    print(f"Found {{len(face_files)}} face images: {{face_files}}")
    
    face_type = "{face_type}"
    detection_model = "{detection_model}"
    similarity_threshold = {similarity_threshold}
    
    root = tk.Tk()
    app = MachineVideoEditorInterface(root, input_path, face_files, face_type, detection_model, similarity_threshold)
    root.mainloop()

if __name__ == "__main__":
    main()
'''
    
    def _create_gui_script(self, input_path: Path, face_files: List[Path], face_type: str, detection_model: str, similarity_threshold: float) -> str:
        """Create a Python script that launches the GUI editor"""
        return f'''
import tkinter as tk
from tkinter import ttk, messagebox, filedialog
import os
import sys
from pathlib import Path
import json

class AdvancedFaceEditor:
    def __init__(self, root, input_path, face_files, face_type, detection_model, similarity_threshold):
        self.root = root
        self.input_path = Path(input_path)
        self.face_files = [Path(f) for f in face_files]
        self.face_type = face_type
        self.detection_model = detection_model
        self.similarity_threshold = similarity_threshold
        
        self.setup_ui()
        self.load_faces()
    
    def setup_ui(self):
        self.root.title("Advanced Face Editor")
        self.root.geometry("1200x800")
        
        # Create main frame
        main_frame = ttk.Frame(self.root)
        main_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)
        
        # Control panel
        control_frame = ttk.LabelFrame(main_frame, text="Controls")
        control_frame.pack(fill=tk.X, pady=(0, 10))
        
        ttk.Button(control_frame, text="Auto Detect Faces", command=self.auto_detect_faces).pack(side=tk.LEFT, padx=5)
        ttk.Button(control_frame, text="Load Model", command=self.load_model).pack(side=tk.LEFT, padx=5)
        ttk.Button(control_frame, text="Group Faces", command=self.group_faces).pack(side=tk.LEFT, padx=5)
        ttk.Button(control_frame, text="Save Changes", command=self.save_changes).pack(side=tk.LEFT, padx=5)
        
        # Face type selection
        type_frame = ttk.LabelFrame(main_frame, text="Face Type")
        type_frame.pack(fill=tk.X, pady=(0, 10))
        
        self.face_type_var = tk.StringVar(value=self.face_type)
        face_types = ["mouth", "half_face", "midfull_face", "full_face", "whole_face", "head"]
        ttk.Combobox(type_frame, textvariable=self.face_type_var, values=face_types, state="readonly").pack(side=tk.LEFT, padx=5)
        
        # Detection model selection
        model_frame = ttk.LabelFrame(main_frame, text="Detection Model")
        model_frame.pack(fill=tk.X, pady=(0, 10))
        
        self.model_var = tk.StringVar(value=self.detection_model)
        models = ["VGGFace2", "OpenCV", "MTCNN"]
        ttk.Combobox(model_frame, textvariable=self.model_var, values=models, state="readonly").pack(side=tk.LEFT, padx=5)
        
        # Similarity threshold
        threshold_frame = ttk.LabelFrame(main_frame, text="Similarity Threshold")
        threshold_frame.pack(fill=tk.X, pady=(0, 10))
        
        self.threshold_var = tk.DoubleVar(value=self.similarity_threshold)
        ttk.Scale(threshold_frame, from_=0.0, to=1.0, variable=self.threshold_var, orient=tk.HORIZONTAL).pack(side=tk.LEFT, padx=5)
        ttk.Label(threshold_frame, textvariable=self.threshold_var).pack(side=tk.LEFT, padx=5)
        
        # Face display area
        display_frame = ttk.LabelFrame(main_frame, text="Face Images")
        display_frame.pack(fill=tk.BOTH, expand=True)
        
        # Create canvas with scrollbar
        canvas = tk.Canvas(display_frame)
        scrollbar = ttk.Scrollbar(display_frame, orient="vertical", command=canvas.yview)
        scrollable_frame = ttk.Frame(canvas)
        
        scrollable_frame.bind(
            "<Configure>",
            lambda e: canvas.configure(scrollregion=canvas.bbox("all"))
        )
        
        canvas.create_window((0, 0), window=scrollable_frame, anchor="nw")
        canvas.configure(yscrollcommand=scrollbar.set)
        
        canvas.pack(side="left", fill="both", expand=True)
        scrollbar.pack(side="right", fill="y")
        
        self.face_frame = scrollable_frame
        self.canvas = canvas
        
        # Status bar
        self.status_var = tk.StringVar(value=f"Loaded {{len(self.face_files)}} face images")
        status_bar = ttk.Label(main_frame, textvariable=self.status_var, relief=tk.SUNKEN)
        status_bar.pack(fill=tk.X, pady=(10, 0))
    
    def load_faces(self):
        """Load and display face images"""
        for i, face_file in enumerate(self.face_files):
            if i >= 50:  # Limit display to first 50 faces
                break
                
            face_frame = ttk.Frame(self.face_frame)
            face_frame.pack(fill=tk.X, padx=5, pady=2)
            
            # Face image placeholder
            ttk.Label(face_frame, text=f"Face {{i+1}}: {{face_file.name}}").pack(side=tk.LEFT)
            
            # Selection checkbox
            var = tk.BooleanVar()
            ttk.Checkbutton(face_frame, variable=var).pack(side=tk.RIGHT)
            
            # Edit button
            ttk.Button(face_frame, text="Edit", command=lambda f=face_file: self.edit_face(f)).pack(side=tk.RIGHT, padx=5)
    
    def auto_detect_faces(self):
        """Auto detect faces in images"""
        messagebox.showinfo("Auto Detect", f"Auto detecting faces using {{self.model_var.get()}} model...")
        self.status_var.set("Auto detecting faces...")
    
    def load_model(self):
        """Load face detection model"""
        messagebox.showinfo("Load Model", f"Loading {{self.model_var.get()}} model...")
        self.status_var.set(f"Loading {{self.model_var.get()}} model...")
    
    def group_faces(self):
        """Group faces by similarity"""
        messagebox.showinfo("Group Faces", f"Grouping faces with threshold {{self.threshold_var.get():.2f}}...")
        self.status_var.set("Grouping faces by similarity...")
    
    def edit_face(self, face_file):
        """Edit individual face"""
        messagebox.showinfo("Edit Face", f"Editing face: {{face_file.name}}")
    
    def save_changes(self):
        """Save all changes"""
        messagebox.showinfo("Save Changes", "Saving all changes...")
        self.status_var.set("Changes saved successfully")

def main():
    # Get parameters from command line or use defaults
    input_path = sys.argv[1] if len(sys.argv) > 1 else "."
    face_files = sys.argv[2:] if len(sys.argv) > 2 else []
    face_type = "{face_type}"
    detection_model = "{detection_model}"
    similarity_threshold = {similarity_threshold}
    
    root = tk.Tk()
    app = AdvancedFaceEditor(root, input_path, face_files, face_type, detection_model, similarity_threshold)
    root.mainloop()

if __name__ == "__main__":
    main()
'''
    
    @classmethod
    def get_parameter_schema(cls) -> Dict[str, Any]:
        """Return parameter schema for this node type"""
        return {
            "type": "object",
            "properties": {
                "input_dir": {
                    "type": "string",
                    "title": "Input Directory",
                    "description": "Directory containing face images to edit",
                    "format": "directory-path"
                },
                "face_type": {
                    "type": "string",
                    "title": "Face Type",
                    "description": "Type of face detection to use",
                    "enum": ["mouth", "half_face", "midfull_face", "full_face", "whole_face", "head"],
                    "default": "full_face"
                },
                "detection_model": {
                    "type": "string",
                    "title": "Detection Model",
                    "description": "Face detection model to use",
                    "enum": ["VGGFace2", "OpenCV", "MTCNN"],
                    "default": "VGGFace2"
                },
                "similarity_threshold": {
                    "type": "number",
                    "title": "Similarity Threshold",
                    "description": "Threshold for grouping similar faces (0.0-1.0)",
                    "minimum": 0.0,
                    "maximum": 1.0,
                    "default": 0.6
                }
            },
            "required": ["input_dir"]
        }
